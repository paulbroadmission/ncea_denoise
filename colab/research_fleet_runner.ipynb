{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ Autonomous Research Fleet ‚Äî Colab GPU Runner\n",
        "\n",
        "This notebook is the **GPU compute layer** for the Research Agent Fleet.\n",
        "It syncs code from Google Drive, runs training/evaluation, and writes results back.\n",
        "\n",
        "**Do NOT edit this notebook manually** ‚Äî the agent fleet manages `src/` and reads `results/`.\n",
        "\n",
        "## How it works\n",
        "1. Mount Google Drive\n",
        "2. Sync `src/` from Drive to Colab local\n",
        "3. Install dependencies\n",
        "4. Run training or evaluation\n",
        "5. Sync `results/` back to Drive\n",
        "6. Agent fleet picks up results from Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Configuration\n",
        "Set your Google Drive project path here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION ‚Äî Set this to your Drive folder path\n",
        "# ============================================================\n",
        "DRIVE_PROJECT_ROOT = \"research-fleet\"  # relative to /content/drive/MyDrive/\n",
        "\n",
        "# Derived paths (don't change)\n",
        "DRIVE_BASE = f\"/content/drive/MyDrive/{DRIVE_PROJECT_ROOT}\"\n",
        "LOCAL_WORKSPACE = \"/content/workspace\"\n",
        "\n",
        "# What to run: 'train', 'evaluate', or 'both'\n",
        "RUN_MODE = \"both\"\n",
        "\n",
        "# Iteration number (read from orchestrator_state.json automatically)\n",
        "AUTO_DETECT_ITERATION = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "assert os.path.exists(DRIVE_BASE), f\"Drive path not found: {DRIVE_BASE}\\nPlease run colab_sync.sh push first.\"\n",
        "print(f\"‚úÖ Drive mounted. Project root: {DRIVE_BASE}\")\n",
        "!ls {DRIVE_BASE}/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Sync from Drive ‚Üí Colab Local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import shutil, json\n",
        "\n",
        "# Create local workspace\n",
        "os.makedirs(LOCAL_WORKSPACE, exist_ok=True)\n",
        "\n",
        "# Sync src/\n",
        "src_drive = os.path.join(DRIVE_BASE, \"src\")\n",
        "src_local = os.path.join(LOCAL_WORKSPACE, \"src\")\n",
        "if os.path.exists(src_local):\n",
        "    shutil.rmtree(src_local)\n",
        "shutil.copytree(src_drive, src_local)\n",
        "print(f\"‚úÖ Synced src/ ({len(os.listdir(src_local))} files)\")\n",
        "\n",
        "# Sync baselines/ if exists\n",
        "baselines_drive = os.path.join(DRIVE_BASE, \"baselines\")\n",
        "baselines_local = os.path.join(LOCAL_WORKSPACE, \"baselines\")\n",
        "if os.path.exists(baselines_drive) and os.listdir(baselines_drive):\n",
        "    if os.path.exists(baselines_local):\n",
        "        shutil.rmtree(baselines_local)\n",
        "    shutil.copytree(baselines_drive, baselines_local)\n",
        "    print(f\"‚úÖ Synced baselines/\")\n",
        "\n",
        "# Read iteration number\n",
        "state_file = os.path.join(DRIVE_BASE, \"logs\", \"orchestrator_state.json\")\n",
        "if AUTO_DETECT_ITERATION and os.path.exists(state_file):\n",
        "    with open(state_file) as f:\n",
        "        state = json.load(f)\n",
        "    ITERATION = state.get(\"iteration\", 1)\n",
        "    print(f\"‚úÖ Auto-detected iteration: {ITERATION}\")\n",
        "else:\n",
        "    ITERATION = 1\n",
        "    print(f\"‚ö†Ô∏è Using default iteration: {ITERATION}\")\n",
        "\n",
        "# Create results directory for this iteration\n",
        "results_dir = os.path.join(LOCAL_WORKSPACE, \"results\", f\"iteration_{ITERATION:03d}\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "os.makedirs(os.path.join(results_dir, \"checkpoints\"), exist_ok=True)\n",
        "print(f\"‚úÖ Results dir: {results_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "req_file = os.path.join(src_local, \"requirements.txt\")\n",
        "if os.path.exists(req_file):\n",
        "    !pip install -q -r {req_file}\n",
        "    print(\"‚úÖ Dependencies installed\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No requirements.txt found, using Colab defaults\")\n",
        "\n",
        "# Verify GPU\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_mem / 1e9\n",
        "    print(f\"‚úÖ GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
        "else:\n",
        "    print(\"‚ùå No GPU! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Patch config.py to use Colab paths\n",
        "import sys\n",
        "sys.path.insert(0, src_local)\n",
        "\n",
        "# Set environment variables for the training scripts\n",
        "os.environ[\"RESULTS_DIR\"] = results_dir\n",
        "os.environ[\"CHECKPOINT_DIR\"] = os.path.join(results_dir, \"checkpoints\")\n",
        "os.environ[\"DATA_DIR\"] = os.path.join(LOCAL_WORKSPACE, \"baselines\", \"data\")\n",
        "os.environ[\"ITERATION\"] = str(ITERATION)\n",
        "\n",
        "print(f\"‚úÖ Environment ready\")\n",
        "print(f\"   src:        {src_local}\")\n",
        "print(f\"   results:    {results_dir}\")\n",
        "print(f\"   iteration:  {ITERATION}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if RUN_MODE in (\"train\", \"both\"):\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  TRAINING ‚Äî Iteration {ITERATION}\")\n",
        "    print(\"=\"*60)\n",
        "    !cd {src_local} && python train.py\n",
        "    print(\"\\n‚úÖ Training complete\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping training (RUN_MODE={RUN_MODE})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if RUN_MODE in (\"evaluate\", \"both\"):\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  EVALUATION ‚Äî Iteration {ITERATION}\")\n",
        "    print(\"=\"*60)\n",
        "    !cd {src_local} && python evaluate.py\n",
        "    print(\"\\n‚úÖ Evaluation complete\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è Skipping evaluation (RUN_MODE={RUN_MODE})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Run Baselines (if baseline scripts exist)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "baseline_runner = os.path.join(baselines_local, \"run_baselines.py\") if os.path.exists(baselines_local) else None\n",
        "if baseline_runner and os.path.exists(baseline_runner):\n",
        "    print(\"=\"*60)\n",
        "    print(f\"  BASELINES ‚Äî Iteration {ITERATION}\")\n",
        "    print(\"=\"*60)\n",
        "    !cd {baselines_local} && python run_baselines.py\n",
        "    print(\"\\n‚úÖ Baselines complete\")\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è No baseline runner found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Sync Results Back to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copy results back to Drive\n",
        "results_drive = os.path.join(DRIVE_BASE, \"results\", f\"iteration_{ITERATION:03d}\")\n",
        "os.makedirs(results_drive, exist_ok=True)\n",
        "\n",
        "# Sync all result files (but not large checkpoints by default)\n",
        "import glob\n",
        "synced = 0\n",
        "for f in glob.glob(os.path.join(results_dir, \"*\")):\n",
        "    if os.path.isfile(f) and not f.endswith(('.pt', '.pth', '.ckpt')):\n",
        "        shutil.copy2(f, results_drive)\n",
        "        synced += 1\n",
        "\n",
        "# Also sync baseline results if any\n",
        "baseline_results = os.path.join(baselines_local, \"results\") if os.path.exists(baselines_local) else None\n",
        "if baseline_results and os.path.exists(baseline_results):\n",
        "    baseline_results_drive = os.path.join(DRIVE_BASE, \"baselines\", \"results\")\n",
        "    if os.path.exists(baseline_results_drive):\n",
        "        shutil.rmtree(baseline_results_drive)\n",
        "    shutil.copytree(baseline_results, baseline_results_drive)\n",
        "    print(f\"‚úÖ Baseline results synced to Drive\")\n",
        "\n",
        "# Write completion marker\n",
        "marker = {\n",
        "    \"iteration\": ITERATION,\n",
        "    \"status\": \"complete\",\n",
        "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\",\n",
        "    \"files_synced\": synced\n",
        "}\n",
        "with open(os.path.join(results_drive, \"_colab_complete.json\"), \"w\") as f:\n",
        "    json.dump(marker, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Results synced to Drive ({synced} files)\")\n",
        "print(f\"   Path: {results_drive}\")\n",
        "print(f\"\\nüéâ Colab run complete! Agent fleet can now pull results.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Quick Results Preview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show results summary\n",
        "test_results = os.path.join(results_dir, \"test_results.json\")\n",
        "if os.path.exists(test_results):\n",
        "    with open(test_results) as f:\n",
        "        results = json.load(f)\n",
        "    print(\"üìä Test Results:\")\n",
        "    for k, v in results.items():\n",
        "        if isinstance(v, float):\n",
        "            print(f\"   {k}: {v:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {k}: {v}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No test_results.json found\")\n",
        "    print(\"   Check training output above for errors.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
