{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Agent Fleet ‚Äî Colab GPU Runner with Guardian\n",
    "\n",
    "**Coordinated GPU execution for the Autonomous Research Agent Fleet**\n",
    "\n",
    "This notebook:\n",
    "1. Syncs code from Google Drive (pushed by Implementer)\n",
    "2. Runs Guardian pre-flight validation\n",
    "3. Trains model on GPU\n",
    "4. Syncs results back to Drive (for Watchdog audit)\n",
    "5. Writes completion marker for Orchestrator\n",
    "\n",
    "**Do not edit manually** ‚Äî managed by agent fleet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Drive & Read Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print(\"‚úÖ Google Drive mounted\")\n",
    "\n",
    "# Configuration from agent fleet\n",
    "DRIVE_PROJECT_ROOT = \"research-fleet\"  # Must match colab_sync.sh config\n",
    "DRIVE_BASE = f\"/content/drive/MyDrive/{DRIVE_PROJECT_ROOT}\"\n",
    "LOCAL_WORKSPACE = \"/content/workspace\"\n",
    "\n",
    "assert os.path.exists(DRIVE_BASE), f\"‚ùå Drive path not found: {DRIVE_BASE}\\nRun: ./scripts/colab_sync.sh push\"\n",
    "print(f\"‚úÖ Project root: {DRIVE_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Sync from Drive ‚Üí Colab Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create local workspace\n",
    "os.makedirs(LOCAL_WORKSPACE, exist_ok=True)\n",
    "\n",
    "# Read iteration number from orchestrator state\n",
    "state_file = os.path.join(DRIVE_BASE, \"logs\", \"orchestrator_state.json\")\n",
    "if os.path.exists(state_file):\n",
    "    with open(state_file) as f:\n",
    "        state = json.load(f)\n",
    "    ITERATION = state.get(\"iteration\", 1)\n",
    "    print(f\"‚úÖ Read iteration from orchestrator: {ITERATION}\")\nelse:\n",
    "    ITERATION = 1\n",
    "    print(f\"‚ö†Ô∏è No orchestrator_state.json, using default iteration: {ITERATION}\")\n",
    "\n",
    "# Sync src/ from Drive\n",
    "src_drive = os.path.join(DRIVE_BASE, \"src\")\n",
    "src_local = os.path.join(LOCAL_WORKSPACE, \"src\")\n",
    "if os.path.exists(src_local):\n",
    "    shutil.rmtree(src_local)\n",
    "shutil.copytree(src_drive, src_local)\n",
    "print(f\"‚úÖ Synced src/ ({len(os.listdir(src_local))} files)\")\n",
    "\n",
    "# Sync baselines/ if present\n",
    "baselines_drive = os.path.join(DRIVE_BASE, \"baselines\")\n",
    "baselines_local = os.path.join(LOCAL_WORKSPACE, \"baselines\")\n",
    "if os.path.exists(baselines_drive):\n",
    "    if os.path.exists(baselines_local):\n",
    "        shutil.rmtree(baselines_local)\n",
    "    shutil.copytree(baselines_drive, baselines_local)\n",
    "    print(f\"‚úÖ Synced baselines/\")\n",
    "\n",
    "# Create results directory for this iteration\n",
    "results_dir = os.path.join(LOCAL_WORKSPACE, \"results\", f\"iteration_{ITERATION:03d}\")\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(results_dir, \"checkpoints\"), exist_ok=True)\n",
    "print(f\"‚úÖ Results dir: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Check GPU & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GPU VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úÖ GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "else:\n",
    "    print(\"‚ùå NO GPU! Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    raise RuntimeError(\"GPU required\")\n",
    "\n",
    "# Install requirements\n",
    "req_file = os.path.join(src_local, \"requirements.txt\")\n",
    "if os.path.exists(req_file):\n",
    "    !pip install -q -r {req_file}\n",
    "    print(\"‚úÖ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: üõ°Ô∏è RUN GUARDIAN VALIDATION (Watchdog Gate #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GUARDIAN VALIDATION (Watchdog Pre-flight Gate)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"python3\", \"workspace/src/guardian.py\"],\n",
    "    cwd=\"/content\",\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    "    env={**os.environ, \"PYTHONPATH\": src_local}\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(\"\\n‚ùå GUARDIAN FAILED\")\n",
    "    print(result.stderr)\n",
    "    # Still write failure marker so orchestrator knows\n",
    "    failure_marker = {\n",
    "        \"iteration\": ITERATION,\n",
    "        \"status\": \"guardian_failed\",\n",
    "        \"error\": result.stderr[:500],\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    results_drive = os.path.join(DRIVE_BASE, \"results\", f\"iteration_{ITERATION:03d}\")\n",
    "    os.makedirs(results_drive, exist_ok=True)\n",
    "    with open(os.path.join(results_drive, \"_colab_guardian_failed.json\"), \"w\") as f:\n",
    "        json.dump(failure_marker, f, indent=2)\n",
    "    raise RuntimeError(\"Guardian validation failed. See output above.\")\nelse:\n",
    "    print(\"\\n‚úÖ GUARDIAN PASSED ‚Äî Ready for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, src_local)\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"RESULTS_DIR\"] = results_dir\n",
    "os.environ[\"CHECKPOINT_DIR\"] = os.path.join(results_dir, \"checkpoints\")\n",
    "os.environ[\"ITERATION\"] = str(ITERATION)\n",
    "os.environ[\"PYTHONPATH\"] = src_local\n",
    "\n",
    "print(f\"‚úÖ Colab environment ready\")\n",
    "print(f\"   Iteration:     {ITERATION}\")\n",
    "print(f\"   Results dir:   {results_dir}\")\n",
    "print(f\"   Local src:     {src_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Import & Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import DEVICE, NUM_EPOCHS, BATCH_SIZE, LAMBDA_CONSISTENCY\n",
    "from model import create_encoder\n",
    "from data import create_data_loaders\n",
    "from train import Trainer\n",
    "from evaluate import Evaluator\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device:             {DEVICE}\")\n",
    "print(f\"Num Epochs:         {NUM_EPOCHS}\")\n",
    "print(f\"Batch Size:         {BATCH_SIZE}\")\n",
    "print(f\"Lambda Consistency: {LAMBDA_CONSISTENCY}\")\n",
    "print(\"\\n‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING ‚Äî Iteration {ITERATION}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "print(\"\\n[1/4] Loading data...\")\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    dataset_name=\"synthetic\",  # Will implement BETA loading later\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# Create model\n",
    "print(\"[2/4] Creating model...\")\n",
    "model = create_encoder(encoder_type=\"cnn\")\n",
    "\n",
    "# Train\n",
    "print(f\"[3/4] Training on {DEVICE} ({NUM_EPOCHS} epochs)...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    lambda_consistency=LAMBDA_CONSISTENCY,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=os.path.join(results_dir, \"checkpoints\"),\n",
    "    log_dir=results_dir,\n",
    ")\n",
    "\n",
    "history = trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n[4/4] Evaluating...\")\n",
    "evaluator = Evaluator(model, test_loader, device=DEVICE)\n",
    "metrics = evaluator.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Val Accuracy:  {history['best_val_accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy:      {metrics['accuracy']:.4f}\")\n",
    "print(f\"Test F1 Score:      {metrics['f1_score']:.4f}\")\n",
    "print(f\"Test ITR:           {metrics['itr']:.2f} bits/min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Results (Watchdog Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Standardized results format for watchdog audit\n",
    "results_data = {\n",
    "    \"iteration\": ITERATION,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\",\n",
    "    \"device\": DEVICE,\n",
    "    \"training\": {\n",
    "        \"best_val_accuracy\": float(history[\"best_val_accuracy\"]),\n",
    "        \"best_epoch\": int(history[\"best_epoch\"]),\n",
    "        \"num_epochs\": NUM_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lambda_consistency\": LAMBDA_CONSISTENCY,\n",
    "    },\n",
    "    \"test_metrics\": {\n",
    "        \"accuracy\": float(metrics[\"accuracy\"]),\n",
    "        \"f1_score\": float(metrics[\"f1_score\"]),\n",
    "        \"itr\": float(metrics[\"itr\"]),\n",
    "        \"within_class_distance\": float(metrics.get(\"within_class_distance\", 0)),\n",
    "        \"between_class_distance\": float(metrics.get(\"between_class_distance\", 0)),\n",
    "        \"consistency_ratio\": float(metrics.get(\"consistency_ratio\", 0)),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save test results\n",
    "test_results_file = os.path.join(results_dir, \"test_results.json\")\n",
    "with open(test_results_file, \"w\") as f:\n",
    "    json.dump(results_data, f, indent=2)\nprint(f\"‚úÖ Test results: {test_results_file}\")\n",
    "\n",
    "# Also save training history\n",
    "history_file = os.path.join(results_dir, \"training_history.json\")\n",
    "with open(history_file, \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\nprint(f\"‚úÖ Training history: {history_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Sync Results Back to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync results directory back to Drive\n",
    "results_drive = os.path.join(DRIVE_BASE, \"results\", f\"iteration_{ITERATION:03d}\")\n",
    "os.makedirs(results_drive, exist_ok=True)\n",
    "\n",
    "# Copy all result files (except large checkpoints)\n",
    "import glob\n",
    "for f in glob.glob(os.path.join(results_dir, \"*.json\")):\n",
    "    shutil.copy2(f, results_drive)\n",
    "    print(f\"‚úÖ Synced {os.path.basename(f)}\")\n",
    "\n",
    "# Copy best checkpoint if it exists\n",
    "best_ckpt = os.path.join(results_dir, \"checkpoints\", \"best_model.pt\")\n",
    "if os.path.exists(best_ckpt):\n",
    "    shutil.copy2(best_ckpt, os.path.join(results_drive, \"best_model.pt\"))\n",
    "    print(f\"‚úÖ Synced best_model.pt\")\n",
    "\n",
    "print(f\"\\nüìÇ Results synced to Drive: {results_drive}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Write Completion Marker (for Orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write completion marker so orchestrator/watchdog knows training finished\n",
    "completion_marker = {\n",
    "    \"iteration\": ITERATION,\n",
    "    \"status\": \"complete\",\n",
    "    \"gpu\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"none\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"best_val_accuracy\": float(history[\"best_val_accuracy\"]),\n",
    "    \"test_accuracy\": float(metrics[\"accuracy\"]),\n",
    "}\n",
    "\n",
    "marker_file = os.path.join(results_drive, \"_colab_complete.json\")\n",
    "with open(marker_file, \"w\") as f:\n",
    "    json.dump(completion_marker, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Completion marker written: {marker_file}\")\n",
    "print(f\"\\nüéâ Colab run complete!\")\n",
    "print(f\"   Orchestrator/Watchdog can now audit results.\")\n",
    "print(f\"   Run locally: ./scripts/colab_sync.sh pull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COLAB EXECUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "‚úÖ Guardian Validation:     PASSED\n",
    "‚úÖ Training:                COMPLETE\n",
    "‚úÖ Results Saved:           {results_dir}\n",
    "‚úÖ Drive Sync:              COMPLETE\n",
    "‚úÖ Completion Marker:       WRITTEN\n",
    "\n",
    "üìä Final Metrics:\n",
    "   Best Val Accuracy:  {history['best_val_accuracy']:.4f}\n",
    "   Test Accuracy:      {metrics['accuracy']:.4f}\n",
    "   Test F1 Score:      {metrics['f1_score']:.4f}\n",
    "   Test ITR:           {metrics['itr']:.2f} bits/min\n",
    "\n",
    "üîÑ Next Steps:\n",
    "   1. Close this notebook\n",
    "   2. Run locally: ./scripts/colab_sync.sh pull\n",
    "   3. Orchestrator will run Watchdog audits\n",
    "   4. Check: workspace/logs/watchdog_report_*.json\n",
    "\n",
    "üìÇ All files on Drive: {results_drive}\n",
    "\"\"\")\nprint(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
